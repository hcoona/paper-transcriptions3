\PassOptionsToPackage{dvipsnames}{xcolor}
\PassOptionsToPackage{unicode=true,colorlinks=true,urlcolor=blue}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
\documentclass[a4paper,12pt,notitlepage,twoside,openright]{article}

\usepackage{ifxetex}
\ifxetex{}
\else
\errmessage{Must be built with XeLaTeX}
\fi

\input{../common/fonts.tex}
\input{../common/packages.tex}
\usepackage{framed}
\usepackage{marginnote}
\input{../common/setup.tex}

\title{\texttt{std::memory\_order}\\{\footnotesize \url{https://en.cppreference.com/w/cpp/atomic/memory_order}}}
\author{}
\date{January 19, 2020}

\begin{document}
\maketitle

Defined in header \texttt{<atomic>}

\begin{minted}{cpp}
typedef enum memory_order {
  memory_order_relaxed,
  memory_order_consume,
  memory_order_acquire,  // since C++11
  memory_order_release,  // until C++20
  memory_order_acq_rel,
  memory_order_seq_cst
} memory_order;

enum class memory_order : /*unspecified*/ {
  relaxed, consume, acquire, release, acq_rel, seq_cst
};
inline constexpr memory_order memory_order_relaxed = memory_order::relaxed;
inline constexpr memory_order memory_order_consume = memory_order::consume;  // since C++20
inline constexpr memory_order memory_order_acquire = memory_order::acquire;
inline constexpr memory_order memory_order_release = memory_order::release;
inline constexpr memory_order memory_order_acq_rel = memory_order::acq_rel;
inline constexpr memory_order memory_order_seq_cst = memory_order::seq_cst;
\end{minted}

\texttt{std::memory\_order} specifies how memory accesses, including regular, non-atomic memory accesses, are to be ordered around an atomic operation. Absent any constraints on a multi-core system, when multiple threads simultaneously read and write to several variables, one thread can observe the values change in an order different from the order another thread wrote them. Indeed, the apparent order of changes can even differ among multiple reader threads. Some similar effects can occur even on uniprocessor systems due to compiler transformations allowed by the memory model.

The default behavior of all atomic operations in the library provides for \emph{sequentially consistent ordering} (see discussion below). That default can hurt performance, but the library's atomic operations can be given an additional \texttt{std::memory\_order} argument to specify the exact constraints, beyond atomicity, that the compiler and processor must enforce for that operation.

\section{Constants}

Defined in header \texttt{<atomic>}

\begin{longtabu} to \columnwidth {lX}
  \toprule
  \rowfont[c]\bfseries
  Value & Explanation \\\midrule\endhead
  \bottomrule\endfoot
  \texttt{memory\_order\_relaxed} & Relaxed operation: there are no synchronization or ordering constraints imposed on other reads or writes, only this operation's atomicity is guaranteed (see Relaxed ordering below) \\
  \texttt{memory\_order\_consume} & A load operation with this memory order performs a \emph{consume operation} on the affected memory location: no reads or writes in the current thread dependent on the value currently loaded can be reordered before this load. Writes to data-dependent variables in other threads that release the same atomic variable are visible in the current thread. On most platforms, this affects compiler optimizations only (see Release-Consume ordering below) \\
  \texttt{memory\_order\_acquire} & A load operation with this memory order performs the \emph{acquire operation} on the affected memory location: no reads or writes in the current thread can be reordered before this load. All writes in other threads that release the same atomic variable are visible in the current thread (see Release-Acquire ordering below) \\
  \texttt{memory\_order\_release} & A store operation with this memory order performs the \emph{release operation}: no reads or writes in the current thread can be reordered after this store. All writes in the current thread are visible in other threads that acquire the same atomic variable (see Release-Acquire ordering below) and writes that carry a dependency into the atomic variable become visible in other threads that consume the same atomic (see Release-Consume ordering below). \\
  \texttt{memory\_order\_acq\_rel} & A read-modify-write operation with this memory order is both an \emph{acquire operation} and a \emph{release operation}. No memory reads or writes in the current thread can be reordered before or after this store. All writes in other threads that release the same atomic variable are visible before the modification and the modification is visible in other threads that acquire the same atomic variable. \\
  \texttt{memory\_order\_seq\_cst} & A load operation with this memory order performs an \emph{acquire operation}, a store performs a \emph{release operation}, and read-modify-write performs both an \emph{acquire operation} and a \emph{release operation}, plus a single total order exists in which all threads observe all modifications in the same order (see Sequentially-consistent ordering below) \\
\end{longtabu}

\section{Formal description}

Inter-thread synchronization and memory ordering determine how \emph{evaluations} and \emph{side effects} of expressions are ordered between different threads of execution. They are defined in the following terms:

\subsection{Sequenced-before}

Within the same thread, evaluation A may be \emph{sequenced-before} evaluation B, as described in evaluation order.

\subsection{Carries dependency}

Within the same thread, evaluation A that is \emph{sequenced-before} evaluation B may also carry a dependency into B (that is, B depends on A), if any of the following is true

\begin{enumerate}
  \item The value of A is used as an operand of B, except
  \begin{enumerate}
    \item if B is a call to \texttt{std::kill\_dependency}
    \item if A is the left operand of the built-in \texttt{\&\&}, \texttt{||}, \texttt{?:}, or \texttt{,} operators.
  \end{enumerate}
  \item A writes to a scalar object M, B reads from M
  \item A carries dependency into another evaluation X, and X carries dependency into B
\end{enumerate}

\subsection{Modification order}

All modifications to any particular atomic variable occur in a total order that is specific to this one atomic variable.

The following four requirements are guaranteed for all atomic operations:

\begin{enumerate}
  \item \textbf{Write-write coherence:} If evaluation A that modifies some atomic M (a write) \emph{happens-before} evaluation B that modifies M, then A appears earlier than B in the \emph{modification order} of M
  \item \textbf{Read-read coherence:} if a value computation A of some atomic M (a read) \emph{happens-before} a value computation B on M, and if the value of A comes from a write X on M, then the value of B is either the value stored by X, or the value stored by a side effect Y on M that appears later than X in the \emph{modification order} of M.
  \item \textbf{Read-write coherence:} if a value computation A of some atomic M (a read) \emph{happens-before} an operation B on M (a write), then the value of A comes from a side-effect (a write) X that appears earlier than B in the \emph{modification order} of M
  \item \textbf{Write-read coherence:} if a side effect (a write) X on an atomic object M \emph{happens-before} a value computation (a read) B of M, then the evaluation B shall take its value from X or from a side effect Y that follows X in the \emph{modification order} of M
\end{enumerate}

\subsection{Release sequence}

After a \emph{release operation} A is performed on an atomic object M, the longest continuous subsequence of the \emph{modification order} of M that consists of

\begin{enumerate}
  \item Writes performed by the same thread that performed A \textcolor{ForestGreen}{(until C++20)}
  \item Atomic read-modify-write operations made to M by any thread
\end{enumerate}

is known as \emph{release sequence headed by A}

\hypertarget{dependency-ordered-before}{%
\subsection{Dependency-ordered before}\label{dependency-ordered-before}}

Between threads, evaluation A is \emph{dependency-ordered before}
evaluation B if any of the following is true

\begin{enumerate}
\item
  A performs a \emph{release operation} on some atomic M, and, in a
  different thread, B performs a \emph{consume operation} on the same
  atomic M, and B reads a value written by any part of the release
  sequence headed by A.
\item
  A is dependency-ordered before X and X carries a dependency into B.
\end{enumerate}

\hypertarget{inter-thread-happens-before}{%
\subsection{Inter-thread
happens-before}\label{inter-thread-happens-before}}

Between threads, evaluation A \emph{inter-thread happens before}
evaluation B if any of the following is true

\begin{enumerate}
\item
  A \emph{synchronizes-with} B
\item
  A is \emph{dependency-ordered before} B
\item
  A \emph{synchronizes-with} some evaluation X, and X is
  \emph{sequenced-before} B
\item
  A is \emph{sequenced-before} some evaluation X, and X
  \emph{inter-thread happens-before} B
\item
  A \emph{inter-thread happens-before} some evaluation X, and X
  \emph{inter-thread happens-before} B
\end{enumerate}

\hypertarget{happens-before}{%
\subsection{Happens-before}\label{happens-before}}

Regardless of threads, evaluation A \emph{happens-before} evaluation B
if any of the following is true:

\begin{enumerate}

\item
  A is \emph{sequenced-before} B
\item
  A \emph{inter-thread happens before} B
\end{enumerate}

The implementation is required to ensure that the \emph{happens-before}
relation is acyclic, by introducing additional synchronization if
necessary (it can only be necessary if a consume operation is involved,
see \href{http://www.cl.cam.ac.uk/~pes20/cpp/popl085ap-sewell.pdf}{Batty
et al})

If one evaluation modifies a memory location, and the other reads or
modifies the same memory location, and if at least one of the
evaluations is not an atomic operation, the behavior of the program is
undefined (the program has a
\href{https://en.cppreference.com/w/cpp/language/memory_model}{data
race}) unless there exists a \emph{happens-before} relationship between
these two evaluations.

\subsection{Strongly happens-before \textcolor{ForestGreen}{(until C++20)}}

Regardless of threads, evaluation A \emph{strongly happens-before}
evaluation B if any of the following is true:

\begin{enumerate}

\item
  A is \emph{sequenced-before} B
\item
  A \emph{synchronizes-with} B
\item
  A \emph{strongly happens-before} X, and X \emph{strongly
  happens-before} B
\end{enumerate}

\subsection{Simply happens-before \textcolor{ForestGreen}{(since C++20)}}

Regardless of threads, evaluation A \emph{simply happens-before}
evaluation B if any of the following is true:

\begin{enumerate}

\item
  A is \emph{sequenced-before} B
\item
  A \emph{synchronizes-with} B
\item
  A \emph{simply happens-before} X, and X \emph{simply happens-before} B
\end{enumerate}

Note: without consume operations, \emph{simply happens-before} and
\emph{happens-before} relations are the same.

\subsection{Strongly happens-before \textcolor{ForestGreen}{(since C++20)}}

Regardless of threads, evaluation A \emph{strongly happens-before}
evaluation B if any of the following is true:

\begin{enumerate}

\item
  A is \emph{sequenced-before} B
\item
  A \emph{synchronizes with} B, and both A and B are sequentially
  consistent atomic operations
\item
  A is \emph{sequenced-before} X, X \emph{simply happens-before} Y, and
  Y is \emph{sequenced-before} B
\item
  A \emph{strongly happens-before} X, and X \emph{strongly
  happens-before} B
\end{enumerate}

Note: informally, if A \emph{strongly happens-before} B, then A appears
to be evaluated before B in all contexts.

Note: \emph{strongly happens-before} excludes consume operations.

\hypertarget{visible-side-effects}{%
\subsection{Visible side-effects}\label{visible-side-effects}}

The side-effect A on a scalar M (a write) is \emph{visible} with respect
to value computation B on M (a read) if both of the following are true:

\begin{enumerate}

\item
  A \emph{happens-before} B
\item
  There is no other side effect X to M where A \emph{happens-before} X
  and X \emph{happens-before} B
\end{enumerate}

If side-effect A is visible with respect to the value computation B,
then the longest contiguous subset of the side-effects to M, in
\emph{modification order}, where B does not \emph{happen-before} it is
known as the \emph{visible sequence of side-effects}. (the value of M,
determined by B, will be the value stored by one of these side effects)

Note: inter-thread synchronization boils down to preventing data races
(by establishing happens-before relationships) and defining which side
effects become visible under what conditions

\hypertarget{consume-operation}{%
\subsection{Consume operation}\label{consume-operation}}

Atomic load with \texttt{memory\_order\_consume} or stronger is a consume
operation. Note that
\href{https://en.cppreference.com/w/cpp/atomic/atomic_thread_fence}{std::atomic\_thread\_fence}
imposes stronger synchronization requirements than a consume operation.

\hypertarget{acquire-operation}{%
\subsection{Acquire operation}\label{acquire-operation}}

Atomic load with \texttt{memory\_order\_acquire} or stronger is an acquire
operation. The \texttt{lock()} operation on a
\href{https://en.cppreference.com/w/cpp/named_req/Mutex}{\emph{Mutex}}
is also an acquire operation. Note that
\href{https://en.cppreference.com/w/cpp/atomic/atomic_thread_fence}{\texttt{std::atomic\_thread\_fence}}
imposes stronger synchronization requirements than an acquire operation.

\hypertarget{release-operation}{%
\subsection{Release operation}\label{release-operation}}

Atomic store with \texttt{memory\_order\_release} or stronger is a release
operation. The \texttt{unlock()} operation on a
\href{https://en.cppreference.com/w/cpp/named_req/Mutex}{\emph{Mutex}}
is also a release operation. Note that
\href{https://en.cppreference.com/w/cpp/atomic/atomic_thread_fence}{\texttt{std::atomic\_thread\_fence}}
imposes stronger synchronization requirements than a release operation.

\hypertarget{explanation}{%
\section{Explanation}\label{explanation}}

\hypertarget{relaxed-ordering}{%
\subsection{Relaxed ordering}\label{relaxed-ordering}}

Atomic operations tagged \texttt{memory\_order\_relaxed} are not synchronization
operations; they do not impose an order among concurrent memory
accesses. They only guarantee atomicity and modification order
consistency.

For example, with x and y initially zero,

\begin{minted}{cpp}
// Thread 1:
r1 = y.load(std::memory_order_relaxed);  // A
x.store(r1, std::memory_order_relaxed);  // B
// Thread 2:
r2 = x.load(std::memory_order_relaxed);  // C
y.store(42, std::memory_order_relaxed);  // D
\end{minted}

is allowed to produce \texttt{r1 == r2 == 42} because, although A is
\emph{sequenced-before} B within thread 1 and C is \emph{sequenced
before} D within thread 2, nothing prevents D from appearing before A in
the modification order of y, and B from appearing before C in the
modification order of x. The side-effect of D on y could be visible to
the load A in thread 1 while the side effect of B on x could be visible
to the load C in thread 2. In particular, this may occur if D is
completed before C in thread 2, either due to compiler reordering or at
runtime.

\begin{oframed}
\marginnote{\textcolor{ForestGreen}{since C++14}}
Even with relaxed memory model, out-of-thin-air values are not allowed
to circularly depend on their own computations, for example, with x and
y initially zero,

\begin{minted}{cpp}
// Thread 1:
r1 = x.load(std::memory_order_relaxed);
if (r1 == 42) y.store(r1, std::memory_order_relaxed);
// Thread 2:
r2 = y.load(std::memory_order_relaxed);
if (r2 == 42) x.store(42, std::memory_order_relaxed);
\end{minted}

is not allowed to produce \texttt{r1 == r2 == 42} since the store of 42 to y is
only possible if the store to x stores 42, which circularly depends on
the store to y storing 42. Note that until C++14, this was technically
allowed by the specification, but not recommended for implementors.
\end{oframed}

Typical use for relaxed memory ordering is incrementing counters, such
as the reference counters of
\href{https://en.cppreference.com/w/cpp/memory/shared_ptr}{std::shared\_ptr},
since this only requires atomicity, but not ordering or synchronization
(note that decrementing the shared\_ptr counters requires
acquire-release synchronization with the destructor)

\begin{minted}{cpp}
#include <vector>
#include <iostream>
#include <thread>
#include <atomic>

std::atomic<int> cnt = {0};

void f()
{
    for (int n = 0; n < 1000; ++n) {
        cnt.fetch_add(1, std::memory_order_relaxed);
    }
}

int main()
{
    std::vector<std::thread> v;
    for (int n = 0; n < 10; ++n) {
        v.emplace_back(f);
    }
    for (auto& t : v) {
        t.join();
    }
    std::cout << "Final counter value is " << cnt << '\n';
}
\end{minted}

Output:

\begin{verbatim}
Final counter value is 10000
\end{verbatim}

\hypertarget{release-acquire-ordering}{%
\subsection{Release-Acquire ordering}\label{release-acquire-ordering}}

If an atomic store in thread A is tagged \texttt{memory\_order\_release} and an
atomic load in thread B from the same variable is tagged
\texttt{memory\_order\_acquire}, all memory writes (non-atomic and relaxed
atomic) that \emph{happened-before} the atomic store from the point of
view of thread A, become \emph{visible side-effects} in thread B. That
is, once the atomic load is completed, thread B is guaranteed to see
everything thread A wrote to memory.

The synchronization is established only between the threads
\emph{releasing} and \emph{acquiring} the same atomic variable. Other
threads can see different order of memory accesses than either or both
of the synchronized threads.

On strongly-ordered systems --- x86, SPARC TSO, IBM mainframe, etc. ---
release-acquire ordering is automatic for the majority of operations. No
additional CPU instructions are issued for this synchronization mode;
only certain compiler optimizations are affected (e.g., the compiler is
prohibited from moving non-atomic stores past the atomic store-release
or performing non-atomic loads earlier than the atomic load-acquire). On
weakly-ordered systems (ARM, Itanium, PowerPC), special CPU load or
memory fence instructions are used.

Mutual exclusion locks, such as
\href{https://en.cppreference.com/w/cpp/thread/mutex}{\texttt{std::mutex}} or
\href{https://en.cppreference.com/w/cpp/atomic/atomic_flag}{atomic
spinlock}, are an example of release-acquire synchronization: when the
lock is released by thread A and acquired by thread B, everything that
took place in the critical section (before the release) in the context
of thread A has to be visible to thread B (after the acquire) which is
executing the same critical section.

\begin{minted}{cpp}
#include <thread>
#include <atomic>
#include <cassert>
#include <string>

std::atomic<std::string*> ptr;
int data;

void producer()
{
    std::string* p  = new std::string("Hello");
    data = 42;
    ptr.store(p, std::memory_order_release);
}

void consumer()
{
    std::string* p2;
    while (!(p2 = ptr.load(std::memory_order_acquire)))
        ;
    assert(*p2 == "Hello"); // never fires
    assert(data == 42); // never fires
}

int main()
{
    std::thread t1(producer);
    std::thread t2(consumer);
    t1.join(); t2.join();
}
\end{minted}

The following example demonstrates transitive release-acquire ordering
across three threads

\begin{minted}{cpp}
#include <thread>
#include <atomic>
#include <cassert>
#include <vector>

std::vector<int> data;
std::atomic<int> flag = {0};

void thread_1()
{
    data.push_back(42);
    flag.store(1, std::memory_order_release);
}

void thread_2()
{
    int expected=1;
    while (!flag.compare_exchange_strong(expected, 2, std::memory_order_acq_rel)) {
        expected = 1;
    }
}

void thread_3()
{
    while (flag.load(std::memory_order_acquire) < 2)
        ;
    assert(data.at(0) == 42); // will never fire
}

int main()
{
    std::thread a(thread_1);
    std::thread b(thread_2);
    std::thread c(thread_3);
    a.join(); b.join(); c.join();
}
\end{minted}

\hypertarget{release-consume-ordering}{%
\subsection{Release-Consume ordering}\label{release-consume-ordering}}

If an atomic store in thread A is tagged \texttt{memory\_order\_release} and an
atomic load in thread B from the same variable is tagged
\texttt{memory\_order\_consume}, all memory writes (non-atomic and relaxed
atomic) that are \emph{dependency-ordered-before} the atomic store from
the point of view of thread A, become \emph{visible side-effects} within
those operations in thread B into which the load operation \emph{carries
dependency}, that is, once the atomic load is completed, those operators
and functions in thread B that use the value obtained from the load are
guaranteed to see what thread A wrote to memory.

The synchronization is established only between the threads
\emph{releasing} and \emph{consuming} the same atomic variable. Other
threads can see different order of memory accesses than either or both
of the synchronized threads.

On all mainstream CPUs other than DEC Alpha, dependency ordering is
automatic, no additional CPU instructions are issued for this
synchronization mode, only certain compiler optimizations are affected
(e.g. the compiler is prohibited from performing speculative loads on
the objects that are involved in the dependency chain).

Typical use cases for this ordering involve read access to rarely
written concurrent data structures (routing tables, configuration,
security policies, firewall rules, etc) and publisher-subscriber
situations with pointer-mediated publication, that is, when the producer
publishes a pointer through which the consumer can access information:
there is no need to make everything else the producer wrote to memory
visible to the consumer (which may be an expensive operation on
weakly-ordered architectures). An example of such scenario is
\href{https://en.wikipedia.org/wiki/Read-copy-update}{rcu\_dereference}.

See also
\href{https://en.cppreference.com/w/cpp/atomic/kill_dependency}{\texttt{std::kill\_dependency}}
and {[}{[}carries\_dependency{]}{]} for fine-grained dependency chain
control.

Note that currently (2/2015) no known production compilers track
dependency chains: consume operations are lifted to acquire operations.

\begin{oframed}
\marginnote{\textcolor{ForestGreen}{(since C++17)}}
The specification of release-consume ordering is being revised, and the
use of memory\_order\_consume is temporarily discouraged.
\end{oframed}

This example demonstrates dependency-ordered synchronization for
pointer-mediated publication: the integer data is not related to the
pointer to string by a data-dependency relationship, thus its value is
undefined in the consumer.

\begin{minted}{cpp}
#include <thread>
#include <atomic>
#include <cassert>
#include <string>

std::atomic<std::string*> ptr;
int data;

void producer()
{
    std::string* p  = new std::string("Hello");
    data = 42;
    ptr.store(p, std::memory_order_release);
}

void consumer()
{
    std::string* p2;
    while (!(p2 = ptr.load(std::memory_order_consume)))
        ;
    assert(*p2 == "Hello"); // never fires: *p2 carries dependency from ptr
    assert(data == 42); // may or may not fire: data does not carry dependency from ptr
}

int main()
{
    std::thread t1(producer);
    std::thread t2(consumer);
    t1.join(); t2.join();
}
\end{minted}

\hypertarget{sequentially-consistent-ordering}{%
\subsection{Sequentially-consistent
ordering}\label{sequentially-consistent-ordering}}

Atomic operations tagged \texttt{memory\_order\_seq\_cst} not only order memory
the same way as release/acquire ordering (everything that
\emph{happened-before} a store in one thread becomes a \emph{visible
side effect} in the thread that did a load), but also establish a
\emph{single total modification order} of all atomic operations that are
so tagged.

\begin{oframed}
\marginnote{\textcolor{ForestGreen}{(until C++20)}}
Formally,

Each \texttt{memory\_order\_seq\_cst} operation B that loads from atomic variable
M, observes one of the following:

\begin{itemize}
\item
  the result of the last operation A that modified M, which appears
  before B in the single total order
\item
  OR, if there was such an A, B may observe the result of some
  modification on M that is not \texttt{memory\_order\_seq\_cst} and does not
  \emph{happen-before} A
\item
  OR, if there wasn't such an A, B may observe the result of some
  unrelated modification of M that is not \texttt{memory\_order\_seq\_cst}
\end{itemize}

If there was a \texttt{memory\_order\_seq\_cst}
\href{https://en.cppreference.com/w/cpp/atomic/atomic_thread_fence}{\texttt{std::atomic\_thread\_fence}}
operation X \emph{sequenced-before} B, then B observes one of the
following:

\begin{itemize}
\item
  the last \texttt{memory\_order\_seq\_cst} modification of M that appears before
  X in the single total order
\item
  some unrelated modification of M that appears later in M's
  modification order
\end{itemize}

For a pair of atomic operations on M called A and B, where A writes and
B reads M's value, if there are two memory\_order\_seq\_cst
\href{https://en.cppreference.com/w/cpp/atomic/atomic_thread_fence}{\texttt{std::atomic\_thread\_fence}}s
X and Y, and if A is \emph{sequenced-before} X, Y is
\emph{sequenced-before} B, and X appears before Y in the Single Total
Order, then B observes either:

\begin{itemize}
\item
  the effect of A
\item
  some unrelated modification of M that appears after A in M's
  modification order
\end{itemize}

For a pair of atomic modifications of M called A and B, B occurs after A
in M's modification order if

\begin{itemize}
\item
  there is a memory\_order\_seq\_cst
  \href{https://en.cppreference.com/w/cpp/atomic/atomic_thread_fence}{std::atomic\_thread\_fence}
  X such that A is \emph{sequenced-before} X and X appears before B in
  the Single Total Order
\item
  or, there is a memory\_order\_seq\_cst
  \href{https://en.cppreference.com/w/cpp/atomic/atomic_thread_fence}{std::atomic\_thread\_fence}
  Y such that Y is \emph{sequenced-before} B and A appears before Y in
  the Single Total Order
\item
  or, there are memory\_order\_seq\_cst
  \href{https://en.cppreference.com/w/cpp/atomic/atomic_thread_fence}{std::atomic\_thread\_fence}s
  X and Y such that A is \emph{sequenced-before} X, Y is
  \emph{sequenced-before} B, and X appears before Y in the Single Total
  Order.
\end{itemize}

Note that this means that:

\begin{enumerate}

\item
  as soon as atomic operations that are not tagged
  \texttt{memory\_order\_seq\_cst} enter the picture, the sequential consistency
  is lost
\item
  the sequentially-consistent fences are only establishing total
  ordering for the fences themselves, not for the atomic operations in
  the general case (\emph{sequenced-before} is not a cross-thread
  relationship, unlike \emph{happens-before})
\end{enumerate}
\end{oframed}

\begin{oframed}
\marginnote{\textcolor{ForestGreen}{(since C++20)}}
Formally,

An atomic operation A on some atomic object M is
\emph{coherence-ordered-before} another atomic operation B on M if any
of the following is true:

\begin{enumerate}

\item
  A is a modification, and B reads the value stored by A
\item
  A precedes B in the \emph{modification order} of M
\item
  A reads the value stored by an atomic modification X, X precedes B in
  the \emph{modification order}, and A and B are not the same atomic
  read-modify-write operation
\item
  A is \emph{coherence-ordered-before} X, and X is
  \emph{coherence-ordered-before} B
\end{enumerate}

There is a single total order S on all \texttt{memory\_order\_seq\_cst}
operations, including fences, that satisfies the following constraints:

\begin{enumerate}

\item
  if A and B are \texttt{memory\_order\_seq\_cst} operations, and A
  \emph{strongly happens-before} B, then A precedes B in S
\item
  for every pair of atomic operations A and B on an object M, where A is
  \emph{coherence-ordered-before} B:

  \begin{enumerate}

  \item
    if A and B are both \texttt{memory\_order\_seq\_cst} operations, then A
    precedes B in S
  \item
    if A is a \texttt{memory\_order\_seq\_cst} operation, and B
    \emph{happens-before} a \texttt{memory\_order\_seq\_cst} fence Y, then A
    precedes Y in S
  \item
    if a \texttt{memory\_order\_seq\_cst} fence X \emph{happens-before} A, and B
    is a \texttt{memory\_order\_seq\_cst} operation, then X precedes B in S
  \item
    if a \texttt{memory\_order\_seq\_cst} fence X \emph{happens-before} A, and B
    \emph{happens-before} a \texttt{memory\_order\_seq\_cst} fence Y, then X
    precedes Y in S
  \end{enumerate}
\end{enumerate}

The formal definition ensures that:

\begin{enumerate}

\item
  the single total order is consistent with the \emph{modification
  order} of any atomic object
\item
  a \texttt{memory\_order\_seq\_cst} load gets its value either from the last
  \texttt{memory\_order\_seq\_cst} modification, or from some
  non-memory\_order\_seq\_cst modification that does not
  \emph{happen-before} preceding \texttt{memory\_order\_seq\_cst} modifications
\end{enumerate}

The single total order might not be consistent with
\emph{happens-before}. This allows more efficient implementation of
memory\_order\_acquire and memory\_order\_release on some CPUs. It can
produce surprising results when memory\_order\_acquire and
memory\_order\_release are mixed with memory\_order\_seq\_cst.

For example, with x and y initially zero,

\begin{minted}{cpp}
// Thread 1:
x.store(1, std::memory_order_seq_cst); // A
y.store(1, std::memory_order_release); // B
// Thread 2:
r1 = y.fetch_add(1, std::memory_order_seq_cst); // C
r2 = y.load(std::memory_order_relaxed); // D
// Thread 3:
y.store(3, std::memory_order_seq_cst); // E
r3 = x.load(std::memory_order_seq_cst); // F
\end{minted}

is allowed to produce \texttt{r1 == 1 \&\& r2 == 3 \&\& r3 == 0}, where A
\emph{happens-before} C, but C precedes A in the single total order
C-E-F-A of \texttt{memory\_order\_seq\_cst} (see
\href{https://plv.mpi-sws.org/scfix/paper.pdf}{Lahav et al}).

Note that:

\begin{enumerate}

\item
  as soon as atomic operations that are not tagged
  \texttt{memory\_order\_seq\_cst} enter the picture, the sequential consistency
  guarantee for the program is lost
\item
  in many cases, \texttt{memory\_order\_seq\_cst} atomic operations are
  reorderable with respect to other atomic operations performed by the
  same thread-(since C++20)
\end{enumerate}
\end{oframed}

Sequential ordering may be necessary for multiple producer-multiple
consumer situations where all consumers must observe the actions of all
producers occurring in the same order.

Total sequential ordering requires a full memory fence CPU instruction
on all multi-core systems. This may become a performance bottleneck
since it forces the affected memory accesses to propagate to every core.

This example demonstrates a situation where sequential ordering is
necessary. Any other ordering may trigger the assert because it would be
possible for the threads c and d to observe changes to the atomics x and
y in opposite order.

\begin{minted}{cpp}
#include <thread>
#include <atomic>
#include <cassert>

std::atomic<bool> x = {false};
std::atomic<bool> y = {false};
std::atomic<int> z = {0};

void write_x()
{
    x.store(true, std::memory_order_seq_cst);
}

void write_y()
{
    y.store(true, std::memory_order_seq_cst);
}

void read_x_then_y()
{
    while (!x.load(std::memory_order_seq_cst))
        ;
    if (y.load(std::memory_order_seq_cst)) {
        ++z;
    }
}

void read_y_then_x()
{
    while (!y.load(std::memory_order_seq_cst))
        ;
    if (x.load(std::memory_order_seq_cst)) {
        ++z;
    }
}

int main()
{
    std::thread a(write_x);
    std::thread b(write_y);
    std::thread c(read_x_then_y);
    std::thread d(read_y_then_x);
    a.join(); b.join(); c.join(); d.join();
    assert(z.load() != 0);  // will never happen
}
\end{minted}

\hypertarget{relationship-with-volatile}{%
\section{Relationship with \texttt{volatile}}\label{relationship-with-volatile}}

Within a thread of execution, accesses (reads and writes) through
\href{https://en.cppreference.com/w/cpp/language/cv}{volatile glvalues}
cannot be reordered past observable side-effects (including other
volatile accesses) that are \emph{sequenced-before} or
\emph{sequenced-after} within the same thread, but this order is not
guaranteed to be observed by another thread, since volatile access does
not establish inter-thread synchronization.

In addition, volatile accesses are not atomic (concurrent read and write
is a \href{https://en.cppreference.com/w/cpp/language/memory_model}{data
race}) and do not order memory (non-volatile memory accesses may be
freely reordered around the volatile access).

One notable exception is Visual Studio, where, with default settings,
every volatile write has release semantics and every volatile read has
acquire semantics
(\href{http://msdn.microsoft.com/en-us/library/12a04hfd(v=vs.100).aspx}{MSDN}),
and thus volatiles may be used for inter-thread synchronization.
Standard volatile semantics are not applicable to multithreaded
programming, although they are sufficient for e.g. communication with a
\href{https://en.cppreference.com/w/cpp/utility/program/signal}{\texttt{std::signal}}
handler that runs in the same thread when applied to \texttt{sig\_atomic\_t}
variables.

\hypertarget{see-also}{%
\section{See also}\label{see-also}}

\href{https://en.cppreference.com/w/c/atomic/memory_order}{C
documentation} for \textbf{memory order}

\hypertarget{external-links}{%
\section{External links}\label{external-links}}

\begin{itemize}
\item
  \href{https://en.wikipedia.org/wiki/MOESI_protocol}{MOESI protocol}
\item
  \href{http://www.cl.cam.ac.uk/~pes20/weakmemory/cacm.pdf}{x86-TSO: A
  Rigorous and Usable Programmer's Model for x86 Multiprocessors} P.
  Sewell et. al., 2010
\item
  \href{http://www.cl.cam.ac.uk/~pes20/ppc-supplemental/test7.pdf}{A
  Tutorial Introduction to the ARM and POWER Relaxed Memory Models} P.
  Sewell et al, 2012
\item
  \href{https://researchspace.auckland.ac.nz/bitstream/handle/2292/11594/MESIF-2009.pdf?sequence=6}{MESIF:
  A Two-Hop Cache Coherency Protocol for Point-to-Point Interconnects}
  J.R. Goodman, H.H.J. Hum, 2009
\end{itemize}

\end{document}
