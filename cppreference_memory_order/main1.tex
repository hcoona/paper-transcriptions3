% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering

\author{}
\date{}

\begin{document}

\hypertarget{dependency-ordered-before}{%
\subsection{Dependency-ordered before}\label{dependency-ordered-before}}

Between threads, evaluation A is \emph{dependency-ordered before}
evaluation B if any of the following is true

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  A performs a \emph{release operation} on some atomic M, and, in a
  different thread, B performs a \emph{consume operation} on the same
  atomic M, and B reads a value written by any part of the release
  sequence headed by A.
\item
  A is dependency-ordered before X and X carries a dependency into B.
\end{enumerate}

\hypertarget{inter-thread-happens-before}{%
\subsection{Inter-thread
happens-before}\label{inter-thread-happens-before}}

Between threads, evaluation A \emph{inter-thread happens before}
evaluation B if any of the following is true

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  A \emph{synchronizes-with} B
\item
  A is \emph{dependency-ordered before} B
\item
  A \emph{synchronizes-with} some evaluation X, and X is
  \emph{sequenced-before} B
\item
  A is \emph{sequenced-before} some evaluation X, and X
  \emph{inter-thread happens-before} B
\item
  A \emph{inter-thread happens-before} some evaluation X, and X
  \emph{inter-thread happens-before} B
\end{enumerate}

\hypertarget{happens-before}{%
\subsection{Happens-before}\label{happens-before}}

Regardless of threads, evaluation A \emph{happens-before} evaluation B
if any of the following is true:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  A is \emph{sequenced-before} B
\item
  A \emph{inter-thread happens before} B
\end{enumerate}

The implementation is required to ensure that the \emph{happens-before}
relation is acyclic, by introducing additional synchronization if
necessary (it can only be necessary if a consume operation is involved,
see \href{http://www.cl.cam.ac.uk/~pes20/cpp/popl085ap-sewell.pdf}{Batty
et al})

If one evaluation modifies a memory location, and the other reads or
modifies the same memory location, and if at least one of the
evaluations is not an atomic operation, the behavior of the program is
undefined (the program has a
\href{https://en.cppreference.com/w/cpp/language/memory_model}{data
race}) unless there exists a \emph{happens-before} relationship between
these two evaluations.

\hypertarget{strongly-happens-before}{%
\subsection{Strongly happens-before}\label{strongly-happens-before}}

Regardless of threads, evaluation A \emph{strongly happens-before}
evaluation B if any of the following is true:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  A is \emph{sequenced-before} B
\item
  A \emph{synchronizes-with} B
\item
  A \emph{strongly happens-before} X, and X \emph{strongly
  happens-before} B
\end{enumerate}

\hypertarget{simply-happens-before}{%
\subsection{Simply happens-before}\label{simply-happens-before}}

Regardless of threads, evaluation A \emph{simply happens-before}
evaluation B if any of the following is true:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  A is \emph{sequenced-before} B
\item
  A \emph{synchronizes-with} B
\item
  A \emph{simply happens-before} X, and X \emph{simply happens-before} B
\end{enumerate}

Note: without consume operations, \emph{simply happens-before} and
\emph{happens-before} relations are the same.

\hypertarget{strongly-happens-before-1}{%
\subsection{Strongly happens-before}\label{strongly-happens-before-1}}

Regardless of threads, evaluation A \emph{strongly happens-before}
evaluation B if any of the following is true:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  A is \emph{sequenced-before} B
\item
  A \emph{synchronizes with} B, and both A and B are sequentially
  consistent atomic operations
\item
  A is \emph{sequenced-before} X, X \emph{simply happens-before} Y, and
  Y is \emph{sequenced-before} B
\item
  A \emph{strongly happens-before} X, and X \emph{strongly
  happens-before} B
\end{enumerate}

Note: informally, if A \emph{strongly happens-before} B, then A appears
to be evaluated before B in all contexts.

\begin{quote}
Note: \emph{strongly happens-before} excludes consume operations.
\end{quote}

\hypertarget{visible-side-effects}{%
\subsection{Visible side-effects}\label{visible-side-effects}}

The side-effect A on a scalar M (a write) is \emph{visible} with respect
to value computation B on M (a read) if both of the following are true:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  A \emph{happens-before} B
\item
  There is no other side effect X to M where A \emph{happens-before} X
  and X \emph{happens-before} B
\end{enumerate}

If side-effect A is visible with respect to the value computation B,
then the longest contiguous subset of the side-effects to M, in
\emph{modification order}, where B does not \emph{happen-before} it is
known as the \emph{visible sequence of side-effects}. (the value of M,
determined by B, will be the value stored by one of these side effects)

Note: inter-thread synchronization boils down to preventing data races
(by establishing happens-before relationships) and defining which side
effects become visible under what conditions

\hypertarget{consume-operation}{%
\subsection{Consume operation}\label{consume-operation}}

Atomic load with memory\_order\_consume or stronger is a consume
operation. Note that
\href{https://en.cppreference.com/w/cpp/atomic/atomic_thread_fence}{std::atomic\_thread\_fence}
imposes stronger synchronization requirements than a consume operation.

\hypertarget{acquire-operation}{%
\subsection{Acquire operation}\label{acquire-operation}}

Atomic load with memory\_order\_acquire or stronger is an acquire
operation. The lock() operation on a
\href{https://en.cppreference.com/w/cpp/named_req/Mutex}{\emph{Mutex}}
is also an acquire operation. Note that
\href{https://en.cppreference.com/w/cpp/atomic/atomic_thread_fence}{std::atomic\_thread\_fence}
imposes stronger synchronization requirements than an acquire operation.

\hypertarget{release-operation}{%
\subsection{Release operation}\label{release-operation}}

Atomic store with memory\_order\_release or stronger is a release
operation. The unlock() operation on a
\href{https://en.cppreference.com/w/cpp/named_req/Mutex}{\emph{Mutex}}
is also a release operation. Note that
\href{https://en.cppreference.com/w/cpp/atomic/atomic_thread_fence}{std::atomic\_thread\_fence}
imposes stronger synchronization requirements than a release operation.

\hypertarget{explanation}{%
\section{Explanation}\label{explanation}}

\hypertarget{relaxed-ordering}{%
\subsection{Relaxed ordering}\label{relaxed-ordering}}

Atomic operations tagged memory\_order\_relaxed are not synchronization
operations; they do not impose an order among concurrent memory
accesses. They only guarantee atomicity and modification order
consistency.

For example, with x and y initially zero,

// Thread 1:

r1 = y.load(std::memory\_order\_relaxed); // A

x.store(r1, std::memory\_order\_relaxed); // B

// Thread 2:

r2 = x.load(std::memory\_order\_relaxed); // C

y.store(42, std::memory\_order\_relaxed); // D

is allowed to produce r1 == r2 == 42 because, although A is
\emph{sequenced-before} B within thread 1 and C is \emph{sequenced
before} D within thread 2, nothing prevents D from appearing before A in
the modification order of y, and B from appearing before C in the
modification order of x. The side-effect of D on y could be visible to
the load A in thread 1 while the side effect of B on x could be visible
to the load C in thread 2. In particular, this may occur if D is
completed before C in thread 2, either due to compiler reordering or at
runtime.

Even with relaxed memory model, out-of-thin-air values are not allowed
to circularly depend on their own computations, for example, with x and
y initially zero,

// Thread 1:

r1 = x.load(std::memory\_order\_relaxed);

if (r1 == 42) y.store(r1, std::memory\_order\_relaxed);

// Thread 2:

r2 = y.load(std::memory\_order\_relaxed);

if (r2 == 42) x.store(42, std::memory\_order\_relaxed);

is not allowed to produce r1 == r2 == 42 since the store of 42 to y is
only possible if the store to x stores 42, which circularly depends on
the store to y storing 42. Note that until C++14, this was technically
allowed by the specification, but not recommended for implementors.
-(since C++14)

Typical use for relaxed memory ordering is incrementing counters, such
as the reference counters of
\href{https://en.cppreference.com/w/cpp/memory/shared_ptr}{std::shared\_ptr},
since this only requires atomicity, but not ordering or synchronization
(note that decrementing the shared\_ptr counters requires
acquire-release synchronization with the destructor)

Run this code

\#include \textless vector\textgreater{}

\#include \textless iostream\textgreater{}

\#include \textless thread\textgreater{}

\#include \textless atomic\textgreater{}

~

\href{http://en.cppreference.com/w/cpp/atomic/atomic}{std::atomic}\textless int\textgreater{}
cnt = \{0\};

~

void f()

\{

for (int n = 0; n \textless{} 1000; ++n) \{

cnt.fetch\_add(1, std::memory\_order\_relaxed);

\}

\}

~

int main()

\{

\href{http://en.cppreference.com/w/cpp/container/vector}{std::vector}\textless{}\href{http://en.cppreference.com/w/cpp/thread/thread}{std::thread}\textgreater{}
v;

for (int n = 0; n \textless{} 10; ++n) \{

v.emplace\_back(f);

\}

for (auto\& t : v) \{

t.join();

\}

\href{http://en.cppreference.com/w/cpp/io/cout}{std::cout}
\textless\textless{} "Final counter value is " \textless\textless{} cnt
\textless\textless{} '\textbackslash n';

\}

Output:

Final counter value is 10000

\hypertarget{release-acquire-ordering}{%
\subsection{Release-Acquire ordering}\label{release-acquire-ordering}}

If an atomic store in thread A is tagged memory\_order\_release and an
atomic load in thread B from the same variable is tagged
memory\_order\_acquire, all memory writes (non-atomic and relaxed
atomic) that \emph{happened-before} the atomic store from the point of
view of thread A, become \emph{visible side-effects} in thread B. That
is, once the atomic load is completed, thread B is guaranteed to see
everything thread A wrote to memory.

The synchronization is established only between the threads
\emph{releasing} and \emph{acquiring} the same atomic variable. Other
threads can see different order of memory accesses than either or both
of the synchronized threads.

On strongly-ordered systems --- x86, SPARC TSO, IBM mainframe, etc. ---
release-acquire ordering is automatic for the majority of operations. No
additional CPU instructions are issued for this synchronization mode;
only certain compiler optimizations are affected (e.g., the compiler is
prohibited from moving non-atomic stores past the atomic store-release
or performing non-atomic loads earlier than the atomic load-acquire). On
weakly-ordered systems (ARM, Itanium, PowerPC), special CPU load or
memory fence instructions are used.

Mutual exclusion locks, such as
\href{https://en.cppreference.com/w/cpp/thread/mutex}{std::mutex} or
\href{https://en.cppreference.com/w/cpp/atomic/atomic_flag}{atomic
spinlock}, are an example of release-acquire synchronization: when the
lock is released by thread A and acquired by thread B, everything that
took place in the critical section (before the release) in the context
of thread A has to be visible to thread B (after the acquire) which is
executing the same critical section.

Run this code

\#include \textless thread\textgreater{}

\#include \textless atomic\textgreater{}

\#include \textless cassert\textgreater{}

\#include \textless string\textgreater{}

~

\href{http://en.cppreference.com/w/cpp/atomic/atomic}{std::atomic}\textless{}\href{http://en.cppreference.com/w/cpp/string/basic_string}{std::string}*\textgreater{}
ptr;

int data;

~

void producer()

\{

\href{http://en.cppreference.com/w/cpp/string/basic_string}{std::string}*
p = new
\href{http://en.cppreference.com/w/cpp/string/basic_string}{std::string}("Hello");

data = 42;

ptr.store(p, std::memory\_order\_release);

\}

~

void consumer()

\{

\href{http://en.cppreference.com/w/cpp/string/basic_string}{std::string}*
p2;

while (!(p2 = ptr.load(std::memory\_order\_acquire)))

;

\href{http://en.cppreference.com/w/cpp/error/assert}{assert}(*p2 ==
"Hello"); // never fires

\href{http://en.cppreference.com/w/cpp/error/assert}{assert}(data ==
42); // never fires

\}

~

int main()

\{

\href{http://en.cppreference.com/w/cpp/thread/thread}{std::thread}
t1(producer);

\href{http://en.cppreference.com/w/cpp/thread/thread}{std::thread}
t2(consumer);

t1.join(); t2.join();

\}

The following example demonstrates transitive release-acquire ordering
across three threads

Run this code

\#include \textless thread\textgreater{}

\#include \textless atomic\textgreater{}

\#include \textless cassert\textgreater{}

\#include \textless vector\textgreater{}

~

\href{http://en.cppreference.com/w/cpp/container/vector}{std::vector}\textless int\textgreater{}
data;

\href{http://en.cppreference.com/w/cpp/atomic/atomic}{std::atomic}\textless int\textgreater{}
flag = \{0\};

~

void thread\_1()

\{

data.push\_back(42);

flag.store(1, std::memory\_order\_release);

\}

~

void thread\_2()

\{

int expected=1;

while (!flag.compare\_exchange\_strong(expected, 2,
std::memory\_order\_acq\_rel)) \{

expected = 1;

\}

\}

~

void thread\_3()

\{

while (flag.load(std::memory\_order\_acquire) \textless{} 2)

;

\href{http://en.cppreference.com/w/cpp/error/assert}{assert}(data.at(0)
== 42); // will never fire

\}

~

int main()

\{

\href{http://en.cppreference.com/w/cpp/thread/thread}{std::thread}
a(thread\_1);

\href{http://en.cppreference.com/w/cpp/thread/thread}{std::thread}
b(thread\_2);

\href{http://en.cppreference.com/w/cpp/thread/thread}{std::thread}
c(thread\_3);

a.join(); b.join(); c.join();

\}

\hypertarget{release-consume-ordering}{%
\subsection{Release-Consume ordering}\label{release-consume-ordering}}

If an atomic store in thread A is tagged memory\_order\_release and an
atomic load in thread B from the same variable is tagged
memory\_order\_consume, all memory writes (non-atomic and relaxed
atomic) that are \emph{dependency-ordered-before} the atomic store from
the point of view of thread A, become \emph{visible side-effects} within
those operations in thread B into which the load operation \emph{carries
dependency}, that is, once the atomic load is completed, those operators
and functions in thread B that use the value obtained from the load are
guaranteed to see what thread A wrote to memory.

The synchronization is established only between the threads
\emph{releasing} and \emph{consuming} the same atomic variable. Other
threads can see different order of memory accesses than either or both
of the synchronized threads.

On all mainstream CPUs other than DEC Alpha, dependency ordering is
automatic, no additional CPU instructions are issued for this
synchronization mode, only certain compiler optimizations are affected
(e.g. the compiler is prohibited from performing speculative loads on
the objects that are involved in the dependency chain).

Typical use cases for this ordering involve read access to rarely
written concurrent data structures (routing tables, configuration,
security policies, firewall rules, etc) and publisher-subscriber
situations with pointer-mediated publication, that is, when the producer
publishes a pointer through which the consumer can access information:
there is no need to make everything else the producer wrote to memory
visible to the consumer (which may be an expensive operation on
weakly-ordered architectures). An example of such scenario is
\href{https://en.wikipedia.org/wiki/Read-copy-update}{rcu\_dereference}.

See also
\href{https://en.cppreference.com/w/cpp/atomic/kill_dependency}{std::kill\_dependency}
and {[}{[}carries\_dependency{]}{]} for fine-grained dependency chain
control.

Note that currently (2/2015) no known production compilers track
dependency chains: consume operations are lifted to acquire operations.

The specification of release-consume ordering is being revised, and the
use of memory\_order\_consume is temporarily discouraged. -(since C++17)

This example demonstrates dependency-ordered synchronization for
pointer-mediated publication: the integer data is not related to the
pointer to string by a data-dependency relationship, thus its value is
undefined in the consumer.

Run this code

\#include \textless thread\textgreater{}

\#include \textless atomic\textgreater{}

\#include \textless cassert\textgreater{}

\#include \textless string\textgreater{}

~

\href{http://en.cppreference.com/w/cpp/atomic/atomic}{std::atomic}\textless{}\href{http://en.cppreference.com/w/cpp/string/basic_string}{std::string}*\textgreater{}
ptr;

int data;

~

void producer()

\{

\href{http://en.cppreference.com/w/cpp/string/basic_string}{std::string}*
p = new
\href{http://en.cppreference.com/w/cpp/string/basic_string}{std::string}("Hello");

data = 42;

ptr.store(p, std::memory\_order\_release);

\}

~

void consumer()

\{

\href{http://en.cppreference.com/w/cpp/string/basic_string}{std::string}*
p2;

while (!(p2 = ptr.load(std::memory\_order\_consume)))

;

\href{http://en.cppreference.com/w/cpp/error/assert}{assert}(*p2 ==
"Hello"); // never fires: *p2 carries dependency from ptr

\href{http://en.cppreference.com/w/cpp/error/assert}{assert}(data ==
42); // may or may not fire: data does not carry dependency from ptr

\}

~

int main()

\{

\href{http://en.cppreference.com/w/cpp/thread/thread}{std::thread}
t1(producer);

\href{http://en.cppreference.com/w/cpp/thread/thread}{std::thread}
t2(consumer);

t1.join(); t2.join();

\}

\hypertarget{sequentially-consistent-ordering}{%
\subsection{Sequentially-consistent
ordering}\label{sequentially-consistent-ordering}}

Atomic operations tagged memory\_order\_seq\_cst not only order memory
the same way as release/acquire ordering (everything that
\emph{happened-before} a store in one thread becomes a \emph{visible
side effect} in the thread that did a load), but also establish a
\emph{single total modification order} of all atomic operations that are
so tagged.

Formally,

Each memory\_order\_seq\_cst operation B that loads from atomic variable
M, observes one of the following:

\begin{itemize}
\item
  the result of the last operation A that modified M, which appears
  before B in the single total order
\item
  OR, if there was such an A, B may observe the result of some
  modification on M that is not memory\_order\_seq\_cst and does not
  \emph{happen-before} A
\item
  OR, if there wasn't such an A, B may observe the result of some
  unrelated modification of M that is not memory\_order\_seq\_cst
\end{itemize}

If there was a memory\_order\_seq\_cst
\href{https://en.cppreference.com/w/cpp/atomic/atomic_thread_fence}{std::atomic\_thread\_fence}
operation X \emph{sequenced-before} B, then B observes one of the
following:

\begin{itemize}
\item
  the last memory\_order\_seq\_cst modification of M that appears before
  X in the single total order
\item
  some unrelated modification of M that appears later in M's
  modification order
\end{itemize}

For a pair of atomic operations on M called A and B, where A writes and
B reads M's value, if there are two memory\_order\_seq\_cst
\href{https://en.cppreference.com/w/cpp/atomic/atomic_thread_fence}{std::atomic\_thread\_fence}s
X and Y, and if A is \emph{sequenced-before} X, Y is
\emph{sequenced-before} B, and X appears before Y in the Single Total
Order, then B observes either:

\begin{itemize}
\item
  the effect of A
\item
  some unrelated modification of M that appears after A in M's
  modification order
\end{itemize}

For a pair of atomic modifications of M called A and B, B occurs after A
in M's modification order if

\begin{itemize}
\item
  there is a memory\_order\_seq\_cst
  \href{https://en.cppreference.com/w/cpp/atomic/atomic_thread_fence}{std::atomic\_thread\_fence}
  X such that A is \emph{sequenced-before} X and X appears before B in
  the Single Total Order
\item
  or, there is a memory\_order\_seq\_cst
  \href{https://en.cppreference.com/w/cpp/atomic/atomic_thread_fence}{std::atomic\_thread\_fence}
  Y such that Y is \emph{sequenced-before} B and A appears before Y in
  the Single Total Order
\item
  or, there are memory\_order\_seq\_cst
  \href{https://en.cppreference.com/w/cpp/atomic/atomic_thread_fence}{std::atomic\_thread\_fence}s
  X and Y such that A is \emph{sequenced-before} X, Y is
  \emph{sequenced-before} B, and X appears before Y in the Single Total
  Order.
\end{itemize}

Note that this means that:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  as soon as atomic operations that are not tagged
  memory\_order\_seq\_cst enter the picture, the sequential consistency
  is lost
\item
  the sequentially-consistent fences are only establishing total
  ordering for the fences themselves, not for the atomic operations in
  the general case (\emph{sequenced-before} is not a cross-thread
  relationship, unlike \emph{happens-before})-(until C++20)
\end{enumerate}

Formally,

An atomic operation A on some atomic object M is
\emph{coherence-ordered-before} another atomic operation B on M if any
of the following is true:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  A is a modification, and B reads the value stored by A
\item
  A precedes B in the \emph{modification order} of M
\item
  A reads the value stored by an atomic modification X, X precedes B in
  the \emph{modification order}, and A and B are not the same atomic
  read-modify-write operation
\item
  A is \emph{coherence-ordered-before} X, and X is
  \emph{coherence-ordered-before} B
\end{enumerate}

There is a single total order S on all memory\_order\_seq\_cst
operations, including fences, that satisfies the following constraints:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  if A and B are memory\_order\_seq\_cst operations, and A
  \emph{strongly happens-before} B, then A precedes B in S
\item
  for every pair of atomic operations A and B on an object M, where A is
  \emph{coherence-ordered-before} B:

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \item
    if A and B are both memory\_order\_seq\_cst operations, then A
    precedes B in S
  \item
    if A is a memory\_order\_seq\_cst operation, and B
    \emph{happens-before} a memory\_order\_seq\_cst fence Y, then A
    precedes Y in S
  \item
    if a memory\_order\_seq\_cst fence X \emph{happens-before} A, and B
    is a memory\_order\_seq\_cst operation, then X precedes B in S
  \item
    if a memory\_order\_seq\_cst fence X \emph{happens-before} A, and B
    \emph{happens-before} a memory\_order\_seq\_cst fence Y, then X
    precedes Y in S
  \end{enumerate}
\end{enumerate}

The formal definition ensures that:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  the single total order is consistent with the \emph{modification
  order} of any atomic object
\item
  a memory\_order\_seq\_cst load gets its value either from the last
  memory\_order\_seq\_cst modification, or from some
  non-memory\_order\_seq\_cst modification that does not
  \emph{happen-before} preceding memory\_order\_seq\_cst modifications
\end{enumerate}

The single total order might not be consistent with
\emph{happens-before}. This allows more efficient implementation of
memory\_order\_acquire and memory\_order\_release on some CPUs. It can
produce surprising results when memory\_order\_acquire and
memory\_order\_release are mixed with memory\_order\_seq\_cst.

For example, with x and y initially zero,

// Thread 1:

x.store(1, std::memory\_order\_seq\_cst); // A

y.store(1, std::memory\_order\_release); // B

// Thread 2:

r1 = y.fetch\_add(1, std::memory\_order\_seq\_cst); // C

r2 = y.load(std::memory\_order\_relaxed); // D

// Thread 3:

y.store(3, std::memory\_order\_seq\_cst); // E

r3 = x.load(std::memory\_order\_seq\_cst); // F

is allowed to produce r1 == 1 \&\& r2 == 3 \&\& r3 == 0, where A
\emph{happens-before} C, but C precedes A in the single total order
C-E-F-A of memory\_order\_seq\_cst (see
\href{https://plv.mpi-sws.org/scfix/paper.pdf}{Lahav et al}).

Note that:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  as soon as atomic operations that are not tagged
  memory\_order\_seq\_cst enter the picture, the sequential consistency
  guarantee for the program is lost
\item
  in many cases, memory\_order\_seq\_cst atomic operations are
  reorderable with respect to other atomic operations performed by the
  same thread-(since C++20)
\end{enumerate}

Sequential ordering may be necessary for multiple producer-multiple
consumer situations where all consumers must observe the actions of all
producers occurring in the same order.

Total sequential ordering requires a full memory fence CPU instruction
on all multi-core systems. This may become a performance bottleneck
since it forces the affected memory accesses to propagate to every core.

This example demonstrates a situation where sequential ordering is
necessary. Any other ordering may trigger the assert because it would be
possible for the threads c and d to observe changes to the atomics x and
y in opposite order.

Run this code

\#include \textless thread\textgreater{}

\#include \textless atomic\textgreater{}

\#include \textless cassert\textgreater{}

~

\href{http://en.cppreference.com/w/cpp/atomic/atomic}{std::atomic}\textless bool\textgreater{}
x = \{false\};

\href{http://en.cppreference.com/w/cpp/atomic/atomic}{std::atomic}\textless bool\textgreater{}
y = \{false\};

\href{http://en.cppreference.com/w/cpp/atomic/atomic}{std::atomic}\textless int\textgreater{}
z = \{0\};

~

void write\_x()

\{

x.store(true, std::memory\_order\_seq\_cst);

\}

~

void write\_y()

\{

y.store(true, std::memory\_order\_seq\_cst);

\}

~

void read\_x\_then\_y()

\{

while (!x.load(std::memory\_order\_seq\_cst))

;

if (y.load(std::memory\_order\_seq\_cst)) \{

++z;

\}

\}

~

void read\_y\_then\_x()

\{

while (!y.load(std::memory\_order\_seq\_cst))

;

if (x.load(std::memory\_order\_seq\_cst)) \{

++z;

\}

\}

~

int main()

\{

\href{http://en.cppreference.com/w/cpp/thread/thread}{std::thread}
a(write\_x);

\href{http://en.cppreference.com/w/cpp/thread/thread}{std::thread}
b(write\_y);

\href{http://en.cppreference.com/w/cpp/thread/thread}{std::thread}
c(read\_x\_then\_y);

\href{http://en.cppreference.com/w/cpp/thread/thread}{std::thread}
d(read\_y\_then\_x);

a.join(); b.join(); c.join(); d.join();

\href{http://en.cppreference.com/w/cpp/error/assert}{assert}(z.load() !=
0); // will never happen

\}

\hypertarget{relationship-with-volatile}{%
\section{Relationship with volatile}\label{relationship-with-volatile}}

Within a thread of execution, accesses (reads and writes) through
\href{https://en.cppreference.com/w/cpp/language/cv}{volatile glvalues}
cannot be reordered past observable side-effects (including other
volatile accesses) that are \emph{sequenced-before} or
\emph{sequenced-after} within the same thread, but this order is not
guaranteed to be observed by another thread, since volatile access does
not establish inter-thread synchronization.

In addition, volatile accesses are not atomic (concurrent read and write
is a \href{https://en.cppreference.com/w/cpp/language/memory_model}{data
race}) and do not order memory (non-volatile memory accesses may be
freely reordered around the volatile access).

One notable exception is Visual Studio, where, with default settings,
every volatile write has release semantics and every volatile read has
acquire semantics
(\href{http://msdn.microsoft.com/en-us/library/12a04hfd(v=vs.100).aspx}{MSDN}),
and thus volatiles may be used for inter-thread synchronization.
Standard volatile semantics are not applicable to multithreaded
programming, although they are sufficient for e.g. communication with a
\href{https://en.cppreference.com/w/cpp/utility/program/signal}{std::signal}
handler that runs in the same thread when applied to sig\_atomic\_t
variables.

\hypertarget{see-also}{%
\section{See also}\label{see-also}}

\begin{longtable}[]{@{}l@{}}
\toprule
\endhead
\href{https://en.cppreference.com/w/c/atomic/memory_order}{C
documentation} for memory order\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{external-links}{%
\section{External links}\label{external-links}}

\begin{itemize}
\item
  \href{https://en.wikipedia.org/wiki/MOESI_protocol}{MOESI protocol}
\end{itemize}

\begin{longtable}[]{@{}ll@{}}
\toprule
\endhead
\begin{minipage}[t]{0.47\columnwidth}\raggedright
\begin{itemize}
\tightlist
\item
\end{itemize}\strut
\end{minipage} & \begin{minipage}[t]{0.47\columnwidth}\raggedright
This section is incomplete\\
Reason: let's find good refs on QPI, MOESI, and maybe Dragon\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\begin{itemize}
\item
  \href{http://www.cl.cam.ac.uk/~pes20/weakmemory/cacm.pdf}{x86-TSO: A
  Rigorous and Usable Programmer's Model for x86 Multiprocessors} P.
  Sewell et. al., 2010
\item
  \href{http://www.cl.cam.ac.uk/~pes20/ppc-supplemental/test7.pdf}{A
  Tutorial Introduction to the ARM and POWER Relaxed Memory Models} P.
  Sewell et al, 2012
\item
  \href{https://researchspace.auckland.ac.nz/bitstream/handle/2292/11594/MESIF-2009.pdf?sequence=6}{MESIF:
  A Two-Hop Cache Coherency Protocol for Point-to-Point Interconnects}
  J.R. Goodman, H.H.J. Hum, 2009
\end{itemize}

\end{document}
